const OpenAI = require("openai");
const axios = require("axios");
const fs = require("fs");

const logger = require("../utils/logger.js");
const prompts = require("../config/prompts.js");

class AICore {
  constructor() {
    this.apiKey = process.env.XAI_API_KEY;
    if (!this.apiKey) {
      throw new Error("API_KEY kh√¥ng ƒë∆∞·ª£c ƒë·∫∑t trong bi·∫øn m√¥i tr∆∞·ªùng");
    }

    this.client = new OpenAI({
      apiKey: this.apiKey,
      baseURL: "https://api.x.ai/v1",
    });

    this.systemPrompt = prompts.system.main;
    this.CoreModel = "grok-3-fast-beta";
    this.imageModel = "grok-2-image-1212";
    this.thinkingModel = "grok-3-mini";
    this.Model = "luna-v2";

    logger.info("AI_CORE", `Initialized with models: ${this.CoreModel}, ${this.thinkingModel}`);
  }

  /**
   * T·∫°o c·∫•u h√¨nh Axios v·ªõi x·ª≠ l√Ω ch·ª©ng ch·ªâ ph√π h·ª£p
   */
  createSecureAxiosInstance(baseURL) {
    const options = {
      baseURL: baseURL || "https://api.x.ai",
      headers: {
        Authorization: `Bearer ${this.apiKey}`,
        "Content-Type": "application/json",
        "anthropic-version": "2025-04-15",
        "User-Agent": `Luna/${this.Model}`,
        Accept: "application/json",
      },
    };

    const certPath = process.env.CUSTOM_CA_CERT_PATH;
    if (certPath && fs.existsSync(certPath)) {
      const ca = fs.readFileSync(certPath);
      options.httpsAgent = new require("https").Agent({ ca });
      logger.info("AI_CORE", `Using custom CA cert: ${certPath}`);
    }

    return axios.create(options);
  }

  /**
   * Th·ª±c hi·ªán t√¨m ki·∫øm web b·∫±ng Live Search
   * @param {string} query - Truy v·∫•n t√¨m ki·∫øm
   * @returns {Promise<Object>} - K·∫øt qu·∫£ t√¨m ki·∫øm v√† metadata
   */
  async performLiveSearch(query) {
    try {
      logger.info("AI_CORE", `Performing Live Search: "${query}"`);

      const searchPrompt = prompts.web.liveSearchPrompt.replace("${query}", query);

      // S·ª≠ d·ª•ng OpenAI SDK format nh∆∞ng v·ªõi Grok's Live Search
      const response = await this.client.chat.completions.create({
        model: this.CoreModel,
        max_tokens: 2048,
        messages: [
          {
            role: "system",
            content: prompts.web.liveSearchSystem,
          },
          {
            role: "user",
            content: searchPrompt,
          },
        ],
        extra_body: {
          search_parameters: {
            mode: "auto",
            max_search_results: 10,
            include_citations: true,
          },
        },
      });

      logger.info("AI_CORE", "Live Search completed successfully");

      return {
        content: response.choices[0].message.content,
        hasSearchResults: true,
        searchMetadata: response.search_metadata || null,
      };
    } catch (error) {
      logger.error("AI_CORE", "Live Search error:", error.message);
      return {
        content: null,
        hasSearchResults: false,
        searchMetadata: null,
        error: error.message,
      };
    }
  }

  /**
   * Ph√¢n t√≠ch tin nh·∫Øn cho ch·ª©c nƒÉng gi√°m s√°t
   * @param {string} prompt - Prompt ph√¢n t√≠ch tin nh·∫Øn
   * @returns {Promise<string>} - K·∫øt qu·∫£ ph√¢n t√≠ch
   */
  async getMonitoringAnalysis(prompt) {
    try {
      logger.debug("AI_CORE", "Processing monitoring analysis");

      const axiosInstance = this.createSecureAxiosInstance("https://api.x.ai");
      const response = await axiosInstance.post("/v1/chat/completions", {
        model: this.CoreModel,
        max_tokens: 1024,
        messages: [
          {
            role: "system",
            content: prompts.system.monitoring,
          },
          {
            role: "user",
            content: prompt,
          },
        ],
      });

      const content = response.data.choices[0].message.content;

      if (!content.includes("VI_PH·∫†M:") && !content.includes("QUY_T·∫ÆC_VI_PH·∫†M:")) {
        return `VI_PH·∫†M: Kh√¥ng\nQUY_T·∫ÆC_VI_PH·∫†M: Kh√¥ng c√≥\nM·ª®C_ƒê·ªò: Kh√¥ng c√≥\nD·∫§U_HI·ªÜU_GI·∫¢_M·∫†O: Kh√¥ng\nƒê·ªÄ_XU·∫§T: Kh√¥ng c·∫ßn h√†nh ƒë·ªông\nL√ù_DO: Kh√¥ng ph√°t hi·ªán vi ph·∫°m`;
      }

      return content;
    } catch (error) {
      logger.error("AI_CORE", "Monitoring analysis error:", error.message);
      return `VI_PH·∫†M: Kh√¥ng\nQUY_T·∫ÆC_VI_PH·∫†M: Kh√¥ng c√≥\nM·ª®C_ƒê·ªò: Kh√¥ng c√≥\nD·∫§U_HI·ªÜU_GI·∫¢_M·∫†O: Kh√¥ng\nƒê·ªÄ_XU·∫§T: Kh√¥ng c·∫ßn h√†nh ƒë·ªông\nL√ù_DO: L·ªói k·∫øt n·ªëi API: ${error.message}`;
    }
  }

  /**
   * X·ª≠ l√Ω chat completion v·ªõi API
   * @param {Array} messages - L·ªãch s·ª≠ tin nh·∫Øn
   * @param {Object} config - C·∫•u h√¨nh API
   * @returns {Promise<string>} - Ph·∫£n h·ªìi t·ª´ API
   */
  async processChatCompletion(messages, config = {}) {
    try {
      const axiosInstance = this.createSecureAxiosInstance("https://api.x.ai");

      const response = await axiosInstance.post("/v1/chat/completions", {
        model: config.model || this.CoreModel,
        max_tokens: config.max_tokens || 2048,
        messages: messages,
        ...config,
      });

      logger.info("AI_CORE", "Chat completion processed successfully");
      return response.data.choices[0].message.content;
    } catch (error) {
      logger.error("AI_CORE", "Chat completion error:", error.message);
      throw new Error(`AI API Error: ${error.message}`);
    }
  }

  /**
   * Nh·∫≠n ph·∫£n h·ªìi v·ªõi qu√° tr√¨nh suy nghƒ© t·ª´ API
   * @param {string} prompt - C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
   * @returns {Promise<string>} - Ph·∫£n h·ªìi v·ªõi qu√° tr√¨nh suy nghƒ©
   */
  async getThinkingResponse(prompt) {
    try {
      logger.info("AI_CORE", "Processing thinking response");

      const thinkingPrompt = prompts.chat.thinking.replace("${promptText}", prompt);
      const messages = [
        {
          role: "system",
          content: this.systemPrompt,
        },
        {
          role: "user",
          content: thinkingPrompt,
        },
      ];

      let content = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
      });

      // Format thinking response
      content = content.replace("[THINKING]", "üí≠ **Qu√° tr√¨nh suy nghƒ©:**\n");
      content = content.replace("[ANSWER]", "\n\n‚ú® **C√¢u tr·∫£ l·ªùi:**\n");

      return content;
    } catch (error) {
      logger.error("AI_CORE", "Thinking response error:", error.message);
      throw error;
    }
  }

  /**
   * Nh·∫≠n ph·∫£n h·ªìi m√£ t·ª´ API
   * @param {string} prompt - Prompt c·ªßa ng∆∞·ªùi d√πng
   * @returns {Promise<string>} - Ph·∫£n h·ªìi m√£ t·ª´ API
   */
  async getCodeCompletion(prompt) {
    try {
      logger.info("AI_CORE", "Processing code completion");

      const enhancedPrompt = `${prompts.code.prefix} ${prompt} ${prompts.code.suffix}`;
      const messages = [
        {
          role: "system",
          content: this.systemPrompt + prompts.code.systemAddition,
        },
        {
          role: "user",
          content: enhancedPrompt,
        },
      ];

      return await this.processChatCompletion(messages, {
        max_tokens: 4000,
      });
    } catch (error) {
      logger.error("AI_CORE", "Code completion error:", error.message);
      throw error;
    }
  }

  /**
   * Ph√¢n t√≠ch n·ªôi dung prompt b·∫±ng AI ƒë·ªÉ ph√°t hi·ªán n·ªôi dung kh√¥ng ph√π h·ª£p
   * @param {string} prompt - Prompt c·∫ßn ph√¢n t√≠ch
   * @returns {Promise<Object>} - K·∫øt qu·∫£ ph√¢n t√≠ch
   */
  async analyzeContentWithAI(prompt) {
    try {
      logger.info("AI_CORE", "Analyzing content with AI");

      const analysisPrompt = prompts.system.analysis.replace("${promptText}", prompt);
      const messages = [
        {
          role: "system",
          content: prompts.system.format,
        },
        {
          role: "user",
          content: analysisPrompt,
        },
      ];

      const content = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
        max_tokens: 1000,
      });

      const analysisResult = JSON.parse(content);
      logger.info("AI_CORE", "Content analysis completed");

      return analysisResult;
    } catch (error) {
      logger.error("AI_CORE", "Content analysis error:", error.message);
      return {
        isInappropriate: false,
        categories: [],
        severity: "low",
        explanation: "Kh√¥ng th·ªÉ ph√¢n t√≠ch do l·ªói: " + error.message,
        suggestedKeywords: [],
      };
    }
  }

  /**
   * D·ªãch prompt ti·∫øng Vi·ªát sang ti·∫øng Anh
   * @param {string} vietnamesePrompt - Prompt ti·∫øng Vi·ªát
   * @returns {Promise<string>} - Prompt ƒë√£ ƒë∆∞·ª£c d·ªãch sang ti·∫øng Anh
   */
  async translatePrompt(vietnamesePrompt) {
    try {
      logger.info("AI_CORE", "Translating Vietnamese prompt");

      const translateRequest = prompts.translation.vietnameseToEnglish.replace(
        "${vietnameseText}",
        vietnamesePrompt
      );

      const messages = [
        {
          role: "user",
          content: translateRequest,
        },
      ];

      const translatedText = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
        max_tokens: 1024,
      });

      const cleanTranslation = translatedText.trim().replace(/^["']|["']$/g, "");
      logger.info("AI_CORE", "Translation completed");

      return cleanTranslation;
    } catch (error) {
      logger.error("AI_CORE", "Translation error:", error.message);
      return vietnamesePrompt;
    }
  }

  /**
   * Tr·∫£ v·ªÅ t√™n m√¥ h√¨nh ƒë∆∞·ª£c hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng
   * @returns {string} - T√™n m√¥ h√¨nh
   */
  getModelName() {
    return this.Model;
  }

  /**
   * X√°c ƒë·ªãnh xem c√≥ n√™n th·ª±c hi·ªán t√¨m ki·∫øm web cho prompt hay kh√¥ng
   * @param {string} prompt - Prompt t·ª´ ng∆∞·ªùi d√πng
   * @returns {boolean} - True n·∫øu n√™n th·ª±c hi·ªán t√¨m ki·∫øm web
   */
  shouldPerformWebSearch(prompt) {
    if (prompt.length < 10) return false;
    const currentTimeKeywords = /(h√¥m nay|ng√†y nay|tu·∫ßn n√†y|th√°ng n√†y|nƒÉm nay|hi·ªán gi·ªù|ƒëang di·ªÖn ra|b√¢y gi·ªù|l√∫c n√†y|today|this week|this month|this year|right now|currently|happening now|at the moment)/i;
    const updateKeywords = /(g·∫ßn ƒë√¢y|hi·ªán t·∫°i|m·ªõi nh·∫•t|c·∫≠p nh·∫≠t|tin t·ª©c|th·ªùi s·ª±|s·ª± ki·ªán|di·ªÖn bi·∫øn|thay ƒë·ªïi|ph√°t tri·ªÉn|xu h∆∞·ªõng|trending|recent|current|latest|update|news|events|changes|developments|breaking)/i;
    const detailKeywords = /(th√¥ng tin v·ªÅ|chi ti·∫øt|t√¨m hi·ªÉu|t√†i li·ªáu|nghi√™n c·ª©u|b√°o c√°o|th·ªëng k√™|d·ªØ li·ªáu|information about|details|research|report|study|documentation|statistics|data)/i;
    const factsKeywords = /(nƒÉm n√†o|khi n√†o|·ªü ƒë√¢u|ai l√†|bao nhi√™u|nh∆∞ th·∫ø n√†o|t·∫°i sao|ƒë·ªãnh nghƒ©a|gi√°|price|cost|when|where|who is|what is|why|how|define|how much|how many)/i;
    const peopleKeywords = /(t√™n th·∫≠t|t√™n ƒë·∫ßy ƒë·ªß|ti·ªÉu s·ª≠|l√Ω l·ªãch|ngh·ªÅ nghi·ªáp|tu·ªïi|sinh nƒÉm|qu√™ qu√°n|gia ƒë√¨nh|real name|full name|biography|career|age|born|hometown|family|streamer|youtuber|tiktoker|influencer|ngh·ªá sƒ©|ca sƒ©|di·ªÖn vi√™n|idol|ng∆∞·ªùi n·ªïi ti·∫øng|celebrity|artist|actor|actress|singer|performer|gamer|content creator)/i;
    const entertainmentKeywords = /(anime|manga|manhua|manhwa|ho·∫°t h√¨nh|phim|series|season|t·∫≠p m·ªõi|episode|chapter m·ªõi|release date|ng√†y ph√°t h√†nh|studio|rating|review|ƒë√°nh gi√°)/i;
    const techKeywords = /(phi√™n b·∫£n|version|update|patch|release|ra m·∫Øt|launch|specs|th√¥ng s·ªë|gi√° b√°n|availability|t√≠nh nƒÉng|features|comparison|so s√°nh)/i;
    const sportsKeywords = /(k·∫øt qu·∫£|result|score|t·ª∑ s·ªë|match|tr·∫≠n ƒë·∫•u|tournament|gi·∫£i ƒë·∫•u|championship|league|season|m√πa gi·∫£i|ranking|b·∫£ng x·∫øp h·∫°ng)/i;
    const financeKeywords = /(gi√°|price|stock|c·ªï phi·∫øu|exchange rate|t·ª∑ gi√°|market|th·ªã tr∆∞·ªùng|economy|kinh t·∫ø|inflation|l·∫°m ph√°t|GDP|unemployment|th·∫•t nghi·ªáp)/i;
    const weatherKeywords = /(th·ªùi ti·∫øt|weather|temperature|nhi·ªát ƒë·ªô|rain|m∆∞a|storm|b√£o|climate|kh√≠ h·∫≠u|forecast|d·ª± b√°o)/i;
    const opinionKeywords = /(b·∫°n nghƒ©|√Ω ki·∫øn c·ªßa b·∫°n|theo b·∫°n|b·∫°n c·∫£m th·∫•y|b·∫°n th√≠ch|b·∫°n c√≥ th·ªÉ|what do you think|in your opinion|your thoughts|how do you feel|do you like|can you|could you)/i;
    const aiCapabilityKeywords = /(b·∫°n c√≥ th·ªÉ|b·∫°n bi·∫øt c√°ch|b·∫°n c√≥ kh·∫£ nƒÉng|b·∫°n l√†m ƒë∆∞·ª£c|can you|are you able|do you know how|are you capable)/i;
    if (opinionKeywords.test(prompt) || aiCapabilityKeywords.test(prompt)) {
      return false;
    }

    return (
      currentTimeKeywords.test(prompt) ||
      updateKeywords.test(prompt) ||
      detailKeywords.test(prompt) ||
      factsKeywords.test(prompt) ||
      peopleKeywords.test(prompt) ||
      entertainmentKeywords.test(prompt) ||
      techKeywords.test(prompt) ||
      sportsKeywords.test(prompt) ||
      financeKeywords.test(prompt) ||
      weatherKeywords.test(prompt)
    );
  }
}

module.exports = new AICore(); 