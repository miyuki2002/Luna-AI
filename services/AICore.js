const OpenAI = require("openai");
const axios = require("axios");
const fs = require("fs");

const logger = require("../utils/logger.js");
const prompts = require("../config/prompts.js");

class AICore {
  constructor() {
    this.apiKey = process.env.XAI_API_KEY;
    if (!this.apiKey) {
      throw new Error("API_KEY kh√¥ng ƒë∆∞·ª£c ƒë·∫∑t trong bi·∫øn m√¥i tr∆∞·ªùng");
    }

    this.client = new OpenAI({
      apiKey: this.apiKey,
      baseURL: "https://api.x.ai/v1",
    });

    this.systemPrompt = prompts.system.main;
    this.CoreModel = "grok-3-fast-latest";
    this.imageModel = "grok-2-vision";
    this.thinkingModel = "grok-3-mini-latest";
    this.Model = "luna-v2";

    logger.info("AI_CORE", `Initialized with models: ${this.CoreModel}, ${this.thinkingModel}`);
  }

  /**
   * Th·ª±c hi·ªán t√¨m ki·∫øm web b·∫±ng Live Search
   * @param {string} query - Truy v·∫•n t√¨m ki·∫øm
   * @returns {Promise<Object>} - K·∫øt qu·∫£ t√¨m ki·∫øm v√† metadata
   */
  async performLiveSearch(query) {
    try {
      logger.info("AI_CORE", `Performing Live Search: "${query}"`);

      const searchPrompt = prompts.web.liveSearchPrompt.replace("${query}", query);

      // S·ª≠ d·ª•ng OpenAI SDK format nh∆∞ng v·ªõi Grok's Live Search
      const response = await this.client.chat.completions.create({
        model: this.CoreModel,
        max_tokens: 2048,
        messages: [
          {
            role: "system",
            content: prompts.web.liveSearchSystem,
          },
          {
            role: "user",
            content: searchPrompt,
          },
        ],
        extra_body: {
          search_parameters: {
            mode: "auto",
            max_search_results: 10,
            include_citations: true,
          },
        },
      });

      logger.info("AI_CORE", "Live Search completed successfully");

      return {
        content: response.choices[0].message.content,
        hasSearchResults: true,
        searchMetadata: response.search_metadata || null,
      };
    } catch (error) {
      logger.error("AI_CORE", "Live Search error:", error.message);
      return {
        content: null,
        hasSearchResults: false,
        searchMetadata: null,
        error: error.message,
      };
    }
  }

  /**
   * Ph√¢n t√≠ch tin nh·∫Øn cho ch·ª©c nƒÉng gi√°m s√°t
   * @param {string} prompt - Prompt ph√¢n t√≠ch tin nh·∫Øn
   * @returns {Promise<string>} - K·∫øt qu·∫£ ph√¢n t√≠ch
   */
  async getMonitoringAnalysis(prompt) {
    try {
      logger.debug("AI_CORE", "Processing monitoring analysis");

      const response = await this.client.chat.completions.create({
        model: this.CoreModel,
        max_tokens: 1024,
        messages: [
          {
            role: "system",
            content: prompts.system.monitoring,
          },
          {
            role: "user",
            content: prompt,
          },
        ],
      });

      const content = response.choices[0].message.content;

      if (!content.includes("VI_PH·∫†M:") && !content.includes("QUY_T·∫ÆC_VI_PH·∫†M:")) {
        return `VI_PH·∫†M: Kh√¥ng\nQUY_T·∫ÆC_VI_PH·∫†M: Kh√¥ng c√≥\nM·ª®C_ƒê·ªò: Kh√¥ng c√≥\nD·∫§U_HI·ªÜU_GI·∫¢_M·∫†O: Kh√¥ng\nƒê·ªÄ_XU·∫§T: Kh√¥ng c·∫ßn h√†nh ƒë·ªông\nL√ù_DO: Kh√¥ng ph√°t hi·ªán vi ph·∫°m`;
      }

      return content;
    } catch (error) {
      logger.error("AI_CORE", "Monitoring analysis error:", error.message);
      return `VI_PH·∫†M: Kh√¥ng\nQUY_T·∫ÆC_VI_PH·∫†M: Kh√¥ng c√≥\nM·ª®C_ƒê·ªò: Kh√¥ng c√≥\nD·∫§U_HI·ªÜU_GI·∫¢_M·∫†O: Kh√¥ng\nƒê·ªÄ_XU·∫§T: Kh√¥ng c·∫ßn h√†nh ƒë·ªông\nL√ù_DO: L·ªói k·∫øt n·ªëi API: ${error.message}`;
    }
  }

  /**
   * X·ª≠ l√Ω chat completion v·ªõi API
   * @param {Array} messages - L·ªãch s·ª≠ tin nh·∫Øn
   * @param {Object} config - C·∫•u h√¨nh API
   * @returns {Promise<string>} - Ph·∫£n h·ªìi t·ª´ API
   */
  async processChatCompletion(messages, config = {}) {
    try {
      const response = await this.client.chat.completions.create({
        model: config.model || this.CoreModel,
        max_tokens: config.max_tokens || 2048,
        messages: messages,
        ...config,
      });

      logger.info("AI_CORE", "Chat completion processed successfully");
      return response.choices[0].message.content;
    } catch (error) {
      logger.error("AI_CORE", "Chat completion error:", error.message);
      throw new Error(`AI API Error: ${error.message}`);
    }
  }

  /**
   * Nh·∫≠n ph·∫£n h·ªìi v·ªõi qu√° tr√¨nh suy nghƒ© t·ª´ API
   * @param {string} prompt - C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
   * @returns {Promise<string>} - Ph·∫£n h·ªìi v·ªõi qu√° tr√¨nh suy nghƒ©
   */
  async getThinkingResponse(prompt) {
    try {
      logger.info("AI_CORE", "Processing thinking response");

      const thinkingPrompt = prompts.chat.thinking.replace("${promptText}", prompt);
      const messages = [
        {
          role: "system",
          content: this.systemPrompt,
        },
        {
          role: "user",
          content: thinkingPrompt,
        },
      ];

      let content = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
      });

      // Format thinking response
      content = content.replace("[THINKING]", "üí≠ **Qu√° tr√¨nh suy nghƒ©:**\n");
      content = content.replace("[ANSWER]", "\n\n‚ú® **C√¢u tr·∫£ l·ªùi:**\n");

      return content;
    } catch (error) {
      logger.error("AI_CORE", "Thinking response error:", error.message);
      throw error;
    }
  }

  /**
   * Nh·∫≠n ph·∫£n h·ªìi m√£ t·ª´ API
   * @param {string} prompt - Prompt c·ªßa ng∆∞·ªùi d√πng
   * @returns {Promise<string>} - Ph·∫£n h·ªìi m√£ t·ª´ API
   */
  async getCodeCompletion(prompt) {
    try {
      logger.info("AI_CORE", "Processing code completion");

      const enhancedPrompt = `${prompts.code.prefix} ${prompt} ${prompts.code.suffix}`;
      const messages = [
        {
          role: "system",
          content: this.systemPrompt + prompts.code.systemAddition,
        },
        {
          role: "user",
          content: enhancedPrompt,
        },
      ];

      return await this.processChatCompletion(messages, {
        max_tokens: 4000,
      });
    } catch (error) {
      logger.error("AI_CORE", "Code completion error:", error.message);
      throw error;
    }
  }

  /**
   * Ph√¢n t√≠ch n·ªôi dung prompt b·∫±ng AI ƒë·ªÉ ph√°t hi·ªán n·ªôi dung kh√¥ng ph√π h·ª£p
   * @param {string} prompt - Prompt c·∫ßn ph√¢n t√≠ch
   * @returns {Promise<Object>} - K·∫øt qu·∫£ ph√¢n t√≠ch
   */
  async analyzeContentWithAI(prompt) {
    try {
      logger.info("AI_CORE", "Analyzing content with AI");

      const analysisPrompt = prompts.system.analysis.replace("${promptText}", prompt);
      const messages = [
        {
          role: "system",
          content: prompts.system.format,
        },
        {
          role: "user",
          content: analysisPrompt,
        },
      ];

      const content = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
        max_tokens: 1000,
      });

      const analysisResult = JSON.parse(content);
      logger.info("AI_CORE", "Content analysis completed");

      return analysisResult;
    } catch (error) {
      logger.error("AI_CORE", "Content analysis error:", error.message);
      return {
        isInappropriate: false,
        categories: [],
        severity: "low",
        explanation: "Kh√¥ng th·ªÉ ph√¢n t√≠ch do l·ªói: " + error.message,
        suggestedKeywords: [],
      };
    }
  }

  /**
   * D·ªãch prompt ti·∫øng Vi·ªát sang ti·∫øng Anh
   * @param {string} vietnamesePrompt - Prompt ti·∫øng Vi·ªát
   * @returns {Promise<string>} - Prompt ƒë√£ ƒë∆∞·ª£c d·ªãch sang ti·∫øng Anh
   */
  async translatePrompt(vietnamesePrompt) {
    try {
      logger.info("AI_CORE", "Translating Vietnamese prompt");

      const translateRequest = prompts.translation.vietnameseToEnglish.replace(
        "${vietnameseText}",
        vietnamesePrompt
      );

      const messages = [
        {
          role: "user",
          content: translateRequest,
        },
      ];

      const translatedText = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
        max_tokens: 1024,
      });

      const cleanTranslation = translatedText.trim().replace(/^["']|["']$/g, "");
      logger.info("AI_CORE", "Translation completed");

      return cleanTranslation;
    } catch (error) {
      logger.error("AI_CORE", "Translation error:", error.message);
      return vietnamesePrompt;
    }
  }

  /**
   * Tr·∫£ v·ªÅ t√™n m√¥ h√¨nh ƒë∆∞·ª£c hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng
   * @returns {string} - T√™n m√¥ h√¨nh
   */
  getModelName() {
    return this.Model;
  }



  /**
   * X√°c ƒë·ªãnh xem c√≥ n√™n th·ª±c hi·ªán t√¨m ki·∫øm web cho prompt hay kh√¥ng
   * @param {string} prompt - Prompt t·ª´ ng∆∞·ªùi d√πng
   * @returns {boolean} - True n·∫øu n√™n th·ª±c hi·ªán t√¨m ki·∫øm web
   */
  shouldPerformWebSearch(prompt) {
    if (prompt.length < 10) return false;

    const urgentInfoKeywords = /(h√¥m nay|ng√†y nay|tu·∫ßn n√†y|th√°ng n√†y|nƒÉm nay|hi·ªán gi·ªù|ƒëang di·ªÖn ra|breaking|today|this week|this month|this year|happening now|trending)/i;

    const informationKeywords = /(g·∫ßn ƒë√¢y|hi·ªán t·∫°i|m·ªõi nh·∫•t|c·∫≠p nh·∫≠t|tin t·ª©c|th·ªùi s·ª±|s·ª± ki·ªán|di·ªÖn bi·∫øn|thay ƒë·ªïi|ph√°t tri·ªÉn|recent|current|latest|update|news|events|changes|developments)/i;

    const detailKeywords = /(th√¥ng tin v·ªÅ|chi ti·∫øt|t√¨m hi·ªÉu|t√†i li·ªáu|nghi√™n c·ª©u|b√°o c√°o|information about|details|research|report|study|documentation)/i;

    const factsKeywords = /(nƒÉm n√†o|khi n√†o|·ªü ƒë√¢u|ai l√†|bao nhi√™u|nh∆∞ th·∫ø n√†o|t·∫°i sao|ƒë·ªãnh nghƒ©a|how many|when|where|who is|what is|why|how|define)/i;

    const opinionKeywords = /(b·∫°n nghƒ©|√Ω ki·∫øn c·ªßa b·∫°n|theo b·∫°n|b·∫°n c·∫£m th·∫•y|b·∫°n th√≠ch|what do you think|in your opinion|your thoughts|how do you feel|do you like)/i;

    const knowledgeCheckKeywords = /(b·∫°n c√≥ bi·∫øt|b·∫°n bi·∫øt|b·∫°n c√≥ hi·ªÉu|b·∫°n hi·ªÉu|b·∫°n c√≥ r√µ|b·∫°n r√µ|do you know|you know|do you understand|you understand|are you familiar with)/i;

    const animeKeywords = /(anime|manga|manhua|manhwa|ho·∫°t h√¨nh|phim ho·∫°t h√¨nh|webtoon|light novel|visual novel|doujinshi|otaku|cosplay|mangaka|seiyuu|studio|season|t·∫≠p|chapter|volume|arc|raw|scan|fansub|vietsub|raw|scanlation)/i;

    const genreKeywords = /(shounen|shoujo|seinen|josei|mecha|isekai|slice of life|harem|reverse harem|romance|action|adventure|fantasy|sci-fi|horror|comedy|drama|psychological|mystery|supernatural|magical girl|sports|school life)/i;

    const studioKeywords = /(ghibli|kyoto animation|shaft|madhouse|bones|ufotable|a-1 pictures|wit studio|mappa|trigger|toei animation|pierrot|production i\.g|sunrise|gainax|ho·∫°t h√¨nh 3d|cgi animation|3d animation)/i;

    const nameKeywords = /(t√™n th·∫≠t|t√™n ƒë·∫ßy ƒë·ªß|t√™n khai sinh|t√™n th∆∞·ªùng g·ªçi|bi·ªát danh|nickname|t√™n ri√™ng|t√™n ngh·ªá sƒ©|stage name|real name|full name|birth name|given name|alias|streamer|youtuber|tiktoker|influencer|ngh·ªá sƒ©|ca sƒ©|di·ªÖn vi√™n|idol|ng∆∞·ªùi n·ªïi ti·∫øng|celebrity|artist|actor|actress|singer|performer|gamer|content creator)/i;

    if (opinionKeywords.test(prompt)) return false;

    return (
      urgentInfoKeywords.test(prompt) ||
      knowledgeCheckKeywords.test(prompt) ||
      animeKeywords.test(prompt) ||
      genreKeywords.test(prompt) ||
      studioKeywords.test(prompt) ||
      nameKeywords.test(prompt) ||
      informationKeywords.test(prompt) ||
      detailKeywords.test(prompt) ||
      factsKeywords.test(prompt)
    );
  }
}

module.exports = new AICore(); 