const OpenAI = require("openai");
const axios = require("axios");
const fs = require("fs");

const logger = require("../utils/logger.js");
const prompts = require("../config/prompts.js");

class AICore {
  constructor() {
    this.apiKey = process.env.XAI_API_KEY;
    if (!this.apiKey) {
      throw new Error("API_KEY kh√¥ng ƒë∆∞·ª£c ƒë·∫∑t trong bi·∫øn m√¥i tr∆∞·ªùng");
    }

    this.client = new OpenAI({
      apiKey: this.apiKey,
      baseURL: "https://api.x.ai/v1",
    });

    this.systemPrompt = prompts.system.main;
    this.CoreModel = "grok-3-fast-beta";
    this.imageModel = "grok-2-image-1212";
    this.thinkingModel = "grok-3-mini";
    this.Model = "luna-v2";

    logger.info("AI_CORE", `Initialized with models: ${this.CoreModel}, ${this.thinkingModel}`);
  }

  /**
   * T·∫°o c·∫•u h√¨nh Axios v·ªõi x·ª≠ l√Ω ch·ª©ng ch·ªâ ph√π h·ª£p
   */
  createSecureAxiosInstance(baseURL) {
    const options = {
      baseURL: baseURL || "https://api.x.ai",
      headers: {
        Authorization: `Bearer ${this.apiKey}`,
        "Content-Type": "application/json",
        "anthropic-version": "2025-04-15",
        "User-Agent": `Luna/${this.Model}`,
        Accept: "application/json",
      },
    };

    const certPath = process.env.CUSTOM_CA_CERT_PATH;
    if (certPath && fs.existsSync(certPath)) {
      const ca = fs.readFileSync(certPath);
      options.httpsAgent = new require("https").Agent({ ca });
      logger.info("AI_CORE", `Using custom CA cert: ${certPath}`);
    }

    return axios.create(options);
  }

  /**
   * Th·ª±c hi·ªán t√¨m ki·∫øm web b·∫±ng Live Search
   * @param {string} query - Truy v·∫•n t√¨m ki·∫øm
   * @returns {Promise<Object>} - K·∫øt qu·∫£ t√¨m ki·∫øm v√† metadata
   */
  async performLiveSearch(query) {
    try {
      logger.info("AI_CORE", `Performing Live Search: "${query}"`);

      const searchPrompt = prompts.web.liveSearchPrompt.replace("${query}", query);

      // S·ª≠ d·ª•ng OpenAI SDK format nh∆∞ng v·ªõi Grok's Live Search
      const response = await this.client.chat.completions.create({
        model: this.CoreModel,
        max_tokens: 2048,
        messages: [
          {
            role: "system",
            content: prompts.web.liveSearchSystem,
          },
          {
            role: "user",
            content: searchPrompt,
          },
        ],
        extra_body: {
          search_parameters: {
            mode: "auto",
            max_search_results: 10,
            include_citations: true,
          },
        },
      });

      logger.info("AI_CORE", "Live Search completed successfully");

      return {
        content: response.choices[0].message.content,
        hasSearchResults: true,
        searchMetadata: response.search_metadata || null,
      };
    } catch (error) {
      logger.error("AI_CORE", "Live Search error:", error.message);
      return {
        content: null,
        hasSearchResults: false,
        searchMetadata: null,
        error: error.message,
      };
    }
  }

  /**
   * Ph√¢n t√≠ch tin nh·∫Øn cho ch·ª©c nƒÉng gi√°m s√°t
   * @param {string} prompt - Prompt ph√¢n t√≠ch tin nh·∫Øn
   * @returns {Promise<string>} - K·∫øt qu·∫£ ph√¢n t√≠ch
   */
  async getMonitoringAnalysis(prompt) {
    try {
      logger.debug("AI_CORE", "Processing monitoring analysis");

      const axiosInstance = this.createSecureAxiosInstance("https://api.x.ai");
      const response = await axiosInstance.post("/v1/chat/completions", {
        model: this.CoreModel,
        max_tokens: 1024,
        messages: [
          {
            role: "system",
            content: prompts.system.monitoring,
          },
          {
            role: "user",
            content: prompt,
          },
        ],
      });

      const content = response.data.choices[0].message.content;

      if (!content.includes("VI_PH·∫†M:") && !content.includes("QUY_T·∫ÆC_VI_PH·∫†M:")) {
        return `VI_PH·∫†M: Kh√¥ng\nQUY_T·∫ÆC_VI_PH·∫†M: Kh√¥ng c√≥\nM·ª®C_ƒê·ªò: Kh√¥ng c√≥\nD·∫§U_HI·ªÜU_GI·∫¢_M·∫†O: Kh√¥ng\nƒê·ªÄ_XU·∫§T: Kh√¥ng c·∫ßn h√†nh ƒë·ªông\nL√ù_DO: Kh√¥ng ph√°t hi·ªán vi ph·∫°m`;
      }

      return content;
    } catch (error) {
      logger.error("AI_CORE", "Monitoring analysis error:", error.message);
      return `VI_PH·∫†M: Kh√¥ng\nQUY_T·∫ÆC_VI_PH·∫†M: Kh√¥ng c√≥\nM·ª®C_ƒê·ªò: Kh√¥ng c√≥\nD·∫§U_HI·ªÜU_GI·∫¢_M·∫†O: Kh√¥ng\nƒê·ªÄ_XU·∫§T: Kh√¥ng c·∫ßn h√†nh ƒë·ªông\nL√ù_DO: L·ªói k·∫øt n·ªëi API: ${error.message}`;
    }
  }

  /**
   * X·ª≠ l√Ω chat completion v·ªõi API
   * @param {Array} messages - L·ªãch s·ª≠ tin nh·∫Øn
   * @param {Object} config - C·∫•u h√¨nh API
   * @returns {Promise<string>} - Ph·∫£n h·ªìi t·ª´ API
   */
  async processChatCompletion(messages, config = {}) {
    try {
      const axiosInstance = this.createSecureAxiosInstance("https://api.x.ai");

      const response = await axiosInstance.post("/v1/chat/completions", {
        model: config.model || this.CoreModel,
        max_tokens: config.max_tokens || 2048,
        messages: messages,
        ...config,
      });

      logger.info("AI_CORE", "Chat completion processed successfully");
      return response.data.choices[0].message.content;
    } catch (error) {
      logger.error("AI_CORE", "Chat completion error:", error.message);
      throw new Error(`AI API Error: ${error.message}`);
    }
  }

  /**
   * Nh·∫≠n ph·∫£n h·ªìi v·ªõi qu√° tr√¨nh suy nghƒ© t·ª´ API
   * @param {string} prompt - C√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
   * @returns {Promise<string>} - Ph·∫£n h·ªìi v·ªõi qu√° tr√¨nh suy nghƒ©
   */
  async getThinkingResponse(prompt) {
    try {
      logger.info("AI_CORE", "Processing thinking response");

      const thinkingPrompt = prompts.chat.thinking.replace("${promptText}", prompt);
      const messages = [
        {
          role: "system",
          content: this.systemPrompt,
        },
        {
          role: "user",
          content: thinkingPrompt,
        },
      ];

      let content = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
      });

      // Format thinking response
      content = content.replace("[THINKING]", "üí≠ **Qu√° tr√¨nh suy nghƒ©:**\n");
      content = content.replace("[ANSWER]", "\n\n‚ú® **C√¢u tr·∫£ l·ªùi:**\n");

      return content;
    } catch (error) {
      logger.error("AI_CORE", "Thinking response error:", error.message);
      throw error;
    }
  }

  /**
   * Nh·∫≠n ph·∫£n h·ªìi m√£ t·ª´ API
   * @param {string} prompt - Prompt c·ªßa ng∆∞·ªùi d√πng
   * @returns {Promise<string>} - Ph·∫£n h·ªìi m√£ t·ª´ API
   */
  async getCodeCompletion(prompt) {
    try {
      logger.info("AI_CORE", "Processing code completion");

      const enhancedPrompt = `${prompts.code.prefix} ${prompt} ${prompts.code.suffix}`;
      const messages = [
        {
          role: "system",
          content: this.systemPrompt + prompts.code.systemAddition,
        },
        {
          role: "user",
          content: enhancedPrompt,
        },
      ];

      return await this.processChatCompletion(messages, {
        max_tokens: 4000,
      });
    } catch (error) {
      logger.error("AI_CORE", "Code completion error:", error.message);
      throw error;
    }
  }

  /**
   * Ph√¢n t√≠ch n·ªôi dung prompt b·∫±ng AI ƒë·ªÉ ph√°t hi·ªán n·ªôi dung kh√¥ng ph√π h·ª£p
   * @param {string} prompt - Prompt c·∫ßn ph√¢n t√≠ch
   * @returns {Promise<Object>} - K·∫øt qu·∫£ ph√¢n t√≠ch
   */
  async analyzeContentWithAI(prompt) {
    try {
      logger.info("AI_CORE", "Analyzing content with AI");

      const analysisPrompt = prompts.system.analysis.replace("${promptText}", prompt);
      const messages = [
        {
          role: "system",
          content: prompts.system.format,
        },
        {
          role: "user",
          content: analysisPrompt,
        },
      ];

      const content = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
        max_tokens: 1000,
      });

      const analysisResult = JSON.parse(content);
      logger.info("AI_CORE", "Content analysis completed");

      return analysisResult;
    } catch (error) {
      logger.error("AI_CORE", "Content analysis error:", error.message);
      return {
        isInappropriate: false,
        categories: [],
        severity: "low",
        explanation: "Kh√¥ng th·ªÉ ph√¢n t√≠ch do l·ªói: " + error.message,
        suggestedKeywords: [],
      };
    }
  }

  /**
   * D·ªãch prompt ti·∫øng Vi·ªát sang ti·∫øng Anh
   * @param {string} vietnamesePrompt - Prompt ti·∫øng Vi·ªát
   * @returns {Promise<string>} - Prompt ƒë√£ ƒë∆∞·ª£c d·ªãch sang ti·∫øng Anh
   */
  async translatePrompt(vietnamesePrompt) {
    try {
      logger.info("AI_CORE", "Translating Vietnamese prompt");

      const translateRequest = prompts.translation.vietnameseToEnglish.replace(
        "${vietnameseText}",
        vietnamesePrompt
      );

      const messages = [
        {
          role: "user",
          content: translateRequest,
        },
      ];

      const translatedText = await this.processChatCompletion(messages, {
        model: this.thinkingModel,
        max_tokens: 1024,
      });

      const cleanTranslation = translatedText.trim().replace(/^["']|["']$/g, "");
      logger.info("AI_CORE", "Translation completed");

      return cleanTranslation;
    } catch (error) {
      logger.error("AI_CORE", "Translation error:", error.message);
      return vietnamesePrompt;
    }
  }

  /**
   * Tr·∫£ v·ªÅ t√™n m√¥ h√¨nh ƒë∆∞·ª£c hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng
   * @returns {string} - T√™n m√¥ h√¨nh
   */
  getModelName() {
    return this.Model;
  }

  /**
   * Test method ƒë·ªÉ ki·ªÉm tra logic shouldPerformWebSearch
   * @param {string} prompt - Prompt ƒë·ªÉ test
   * @returns {Object} - K·∫øt qu·∫£ test v·ªõi l√Ω do
   */
  testWebSearchLogic(prompt) {
    const basicKnowledgeKeywords = /(l√† g√¨|what is|define|ƒë·ªãnh nghƒ©a|gi·∫£i th√≠ch|explain|c√°ch l√†m|how to|h∆∞·ªõng d·∫´n|tutorial|l√Ω thuy·∫øt|theory|kh√°i ni·ªám|concept|nguy√™n l√Ω|principle)/i;
    const aiPersonalKeywords = /(b·∫°n nghƒ©|√Ω ki·∫øn c·ªßa b·∫°n|theo b·∫°n|b·∫°n c·∫£m th·∫•y|b·∫°n th√≠ch|b·∫°n c√≥ th·ªÉ|b·∫°n bi·∫øt c√°ch|b·∫°n c√≥ kh·∫£ nƒÉng|b·∫°n l√†m ƒë∆∞·ª£c|what do you think|in your opinion|your thoughts|how do you feel|do you like|can you|could you|are you able|do you know how|are you capable)/i;
    const programmingKeywords = /(code|l·∫≠p tr√¨nh|programming|javascript|python|html|css|react|nodejs|algorithm|thu·∫≠t to√°n|debug|error|l·ªói|syntax|c√∫ ph√°p)/i;
    const realTimeKeywords = /(h√¥m nay|ng√†y nay|tu·∫ßn n√†y|th√°ng n√†y|nƒÉm nay|hi·ªán gi·ªù|ƒëang di·ªÖn ra|b√¢y gi·ªù|l√∫c n√†y|today|this week|this month|this year|right now|currently|happening now|at the moment|v·ª´a x·∫£y ra|just happened)/i;
    const newsKeywords = /(tin t·ª©c|th·ªùi s·ª±|breaking news|latest news|m·ªõi nh·∫•t|c·∫≠p nh·∫≠t|update|s·ª± ki·ªán|events|di·ªÖn bi·∫øn m·ªõi|recent developments)/i;

    const result = {
      shouldSearch: this.shouldPerformWebSearch(prompt),
      reasons: []
    };

    if (basicKnowledgeKeywords.test(prompt)) {
      result.reasons.push("‚ùå Basic knowledge question - no search needed");
    }
    if (aiPersonalKeywords.test(prompt)) {
      result.reasons.push("‚ùå AI personal question - no search needed");
    }
    if (programmingKeywords.test(prompt)) {
      result.reasons.push("‚ùå Programming question - no search needed");
    }
    if (realTimeKeywords.test(prompt)) {
      result.reasons.push("‚úÖ Real-time information - search needed");
    }
    if (newsKeywords.test(prompt)) {
      result.reasons.push("‚úÖ News/updates - search needed");
    }

    if (result.reasons.length === 0) {
      result.reasons.push("‚ÑπÔ∏è No specific keywords matched");
    }

    return result;
  }

  /**
   * X√°c ƒë·ªãnh xem c√≥ n√™n th·ª±c hi·ªán t√¨m ki·∫øm web cho prompt hay kh√¥ng
   * @param {string} prompt - Prompt t·ª´ ng∆∞·ªùi d√πng
   * @returns {boolean} - True n·∫øu n√™n th·ª±c hi·ªán t√¨m ki·∫øm web
   */
  shouldPerformWebSearch(prompt) {
    if (prompt.length < 10) return false;

    const basicKnowledgeKeywords = /(l√† g√¨|what is|define|ƒë·ªãnh nghƒ©a|gi·∫£i th√≠ch|explain|c√°ch l√†m|how to|h∆∞·ªõng d·∫´n|tutorial|l√Ω thuy·∫øt|theory|kh√°i ni·ªám|concept|nguy√™n l√Ω|principle)/i;
    
    const aiPersonalKeywords = /(b·∫°n nghƒ©|√Ω ki·∫øn c·ªßa b·∫°n|theo b·∫°n|b·∫°n c·∫£m th·∫•y|b·∫°n th√≠ch|b·∫°n c√≥ th·ªÉ|b·∫°n bi·∫øt c√°ch|b·∫°n c√≥ kh·∫£ nƒÉng|b·∫°n l√†m ƒë∆∞·ª£c|what do you think|in your opinion|your thoughts|how do you feel|do you like|can you|could you|are you able|do you know how|are you capable)/i;

    const programmingKeywords = /(code|l·∫≠p tr√¨nh|programming|javascript|python|html|css|react|nodejs|algorithm|thu·∫≠t to√°n|debug|error|l·ªói|syntax|c√∫ ph√°p)/i;

    const realTimeKeywords = /(h√¥m nay|ng√†y nay|tu·∫ßn n√†y|th√°ng n√†y|nƒÉm nay|hi·ªán gi·ªù|ƒëang di·ªÖn ra|b√¢y gi·ªù|l√∫c n√†y|today|this week|this month|this year|right now|currently|happening now|at the moment|v·ª´a x·∫£y ra|just happened)/i;
    
    const newsKeywords = /(tin t·ª©c|th·ªùi s·ª±|breaking news|latest news|m·ªõi nh·∫•t|c·∫≠p nh·∫≠t|update|s·ª± ki·ªán|events|di·ªÖn bi·∫øn m·ªõi|recent developments)/i;
    
    const currentPeopleKeywords = /(streamer|youtuber|tiktoker|influencer|ngh·ªá sƒ©|ca sƒ©|di·ªÖn vi√™n|idol|ng∆∞·ªùi n·ªïi ti·∫øng|celebrity|g·∫ßn ƒë√¢y|recently)/i;
    
    const marketKeywords = /(gi√° hi·ªán t·∫°i|current price|gi√° h√¥m nay|today's price|stock price|c·ªï phi·∫øu|exchange rate|t·ª∑ gi√°|market today|th·ªã tr∆∞·ªùng h√¥m nay)/i;
    
    const currentWeatherKeywords = /(th·ªùi ti·∫øt h√¥m nay|today's weather|th·ªùi ti·∫øt hi·ªán t·∫°i|current weather|d·ª± b√°o th·ªùi ti·∫øt|weather forecast)/i;

    const sportsResultsKeywords = /(k·∫øt qu·∫£ tr·∫≠n|match result|t·ª∑ s·ªë|score|championship|gi·∫£i ƒë·∫•u|tournament|m√πa gi·∫£i|season|g·∫ßn ƒë√¢y|recent)/i;

    if (basicKnowledgeKeywords.test(prompt) || 
        aiPersonalKeywords.test(prompt) || 
        programmingKeywords.test(prompt)) {
      return false;
    }

    return (
      realTimeKeywords.test(prompt) ||
      newsKeywords.test(prompt) ||
      (currentPeopleKeywords.test(prompt) && realTimeKeywords.test(prompt)) ||
      marketKeywords.test(prompt) ||
      currentWeatherKeywords.test(prompt) ||
      sportsResultsKeywords.test(prompt)
    );
  }
}

module.exports = new AICore(); 